{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sys\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modify the POS tags by using only the first two letters of a tag,\n",
    "# which represent the broad class of POS tags in the Brown corpus.\n",
    "# Also switch the order of word tag pairs to be tag word to conform\n",
    "# with transition and emission probabilities. Add a leading period\n",
    "# to give the first sentence in the corpus a starting transition\n",
    "# probability.\n",
    "tagged_corpus = [(\".\", \".\")]\n",
    "for sentence in brown.tagged_sents():\n",
    "    tagged_corpus.extend([(tag[:2], word.lower()) for (word, tag) in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the transition probability matrix \n",
    "## Transition probability: P(xt | x{t-1})\n",
    "pos_tags = [tag for (tag, word) in tagged_corpus]\n",
    "transition_cond_freq_dist = nltk.ConditionalFreqDist(nltk.bigrams(pos_tags))\n",
    "transition_matrix = nltk.ConditionalProbDist(transition_cond_freq_dist, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the emission probability matrix\n",
    "## Emission probability: P(yt | xt)\n",
    "emission_cond_freq_dist = nltk.ConditionalFreqDist(tagged_corpus)\n",
    "emission_matrix = nltk.ConditionalProbDist(emission_cond_freq_dist, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \n",
      "The \n",
      "dog \n",
      "ate \n",
      "good \n",
      "food \n",
      "\n",
      "\n",
      "POS tags: \n",
      "AT \n",
      "NN \n",
      "VB \n",
      "JJ \n",
      "NN \n",
      "\n",
      "\n",
      "Probability: 3.0419356504999104e-18\n"
     ]
    }
   ],
   "source": [
    "### Implement the Viterbi algorithm.\n",
    "# Algorithm set up\n",
    "distinct_tags = set(pos_tags)\n",
    "sentence = [\"The\", \"dog\", \"ate\", \"good\", \"food\"]\n",
    "lower_sent = [word.lower() for word in sentence]\n",
    "# In the Stanford pseudo-code, tag_probs is 'viterbi' and actual_tags is 'backpointer'\n",
    "tag_probs = [{}]\n",
    "actual_tags = [{}]\n",
    "\n",
    "# Initialization step\n",
    "for tag in distinct_tags:\n",
    "    tag_probs[0][tag] = transition_matrix[\".\"].prob(tag) * emission_matrix[tag].prob(lower_sent[0])\n",
    "    actual_tags[0][tag] = None\n",
    "    \n",
    "# Recursion step\n",
    "for index in range(1, len(lower_sent)):\n",
    "    this_tag_prob = {}\n",
    "    this_actual_tag = {}\n",
    "    prev_tag_prob = tag_probs[-1]\n",
    "    \n",
    "    for tag in distinct_tags:\n",
    "        best_prev = max(prev_tag_prob.keys(), key = lambda prev_tag: prev_tag_prob[prev_tag] * transition_matrix[prev_tag].prob(tag) * emission_matrix[tag].prob(lower_sent[index]))\n",
    "        this_actual_tag[tag] = best_prev\n",
    "        this_tag_prob[tag] = prev_tag_prob[best_prev] * transition_matrix[best_prev].prob(tag) * emission_matrix[tag].prob(lower_sent[index])\n",
    "    \n",
    "    tag_probs.append(this_tag_prob)\n",
    "    actual_tags.append(this_actual_tag)\n",
    "\n",
    "# Termination step\n",
    "prev_tag_prob = tag_probs[-1]\n",
    "best_prev = max(prev_tag_prob.keys(), key = lambda prev_tag: prev_tag_prob[prev_tag] * transition_matrix[prev_tag].prob(\".\"))\n",
    "best_tags_prob = prev_tag_prob[best_prev] * transition_matrix[best_prev].prob(\".\")\n",
    "# best_tags is the list of tags or hidden states that will be returned\n",
    "best_tags = [\".\", best_prev]\n",
    "\n",
    "# Go backwards through actual_tags to figure out best tag for each word\n",
    "# and populate best_tags\n",
    "actual_tags.reverse()\n",
    "this_best_tag = best_prev\n",
    "for tag in actual_tags:\n",
    "    best_tags.append(tag[this_best_tag])\n",
    "    this_best_tag = tag[this_best_tag]\n",
    "# Reverse best_tags to match pos tags with word order\n",
    "best_tags.reverse()\n",
    "\n",
    "print(\"Sentence: \")\n",
    "for word in sentence: \n",
    "    print(word + \" \")\n",
    "print(\"\\n\")\n",
    "print(\"POS tags: \")\n",
    "for tag in best_tags:\n",
    "    if tag and tag != \".\":\n",
    "        print(tag + \" \")\n",
    "print(\"\\n\")\n",
    "print(\"Probability: \" + str(best_tags_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Input sentence\n",
    "1) Forward viterbi\n",
    "3) range to include from brown corpus\n",
    "4) choose number of top pos tags per observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
